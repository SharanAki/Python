{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://money.cnn.com/data/markets/dow')\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.google.com')\n",
    "r.status_code\n",
    "r.headers['content-type']\n",
    "r.encoding\n",
    "r.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re = requests.get('https://edition.cnn.com/markets')\n",
    "print(re.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png')\n",
    "with open('google.png', 'wb') as fp:\n",
    "     fp.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "re = requests.get('https://www.zhihu.com')\n",
    "print(re.status_code)\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.83 Safari/535.11\"}\n",
    "re = requests.get('https://www.zhihu.com', headers = headers)\n",
    "print(re.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page title: Example Page\n",
      "Header text: Hello World!\n",
      "Paragraph text: This is some example content.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Example Page</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Hello World!</h1>\n",
    "    <p>This is some example content.</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html_doc, \"html.parser\")\n",
    "\n",
    "title = soup.find(\"title\").string\n",
    "print(\"Page title:\", title)\n",
    "\n",
    "header = soup.find(\"h1\").string\n",
    "print(\"Header text:\", header)\n",
    "\n",
    "paragraph = soup.find(\"p\").string\n",
    "print(\"Paragraph text:\", paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shawshank Redemption-1994\n",
      "--------------------\n",
      "The Godfather-1972\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top\"\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "movies = soup.find_all(\"td\", class_=\"titleColumn\")\n",
    "\n",
    "for movie in movies:\n",
    "    title = movie.find(\"a\").string\n",
    "    year = movie.find(\"span\", class_=\"secondaryInfo\").string\n",
    "    year = year.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    with open('movie.txt','a+') as f:\n",
    "        f.writelines(title + '-'+ year + '\\n')\n",
    "        f.writelines('-'*20 + '\\n')\n",
    "\n",
    "with open('movie.txt','r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Year Rating\n",
      "0                           The Shawshank Redemption  1994    9.2\n",
      "1                                      The Godfather  1972    9.2\n",
      "2                                    The Dark Knight  2008    9.0\n",
      "3                              The Godfather Part II  1974    9.0\n",
      "4                                       12 Angry Men  1957    9.0\n",
      "5                                   Schindler's List  1993    8.9\n",
      "6      The Lord of the Rings: The Return of the King  2003    8.9\n",
      "7                                       Pulp Fiction  1994    8.8\n",
      "8  The Lord of the Rings: The Fellowship of the Ring  2001    8.8\n",
      "9                    Il buono, il brutto, il cattivo  1966    8.8\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top\"\n",
    "\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "\n",
    "movies = soup.find_all(\"td\", class_=\"titleColumn\")\n",
    "movies1 = soup.find_all(\"td\", class_=\"ratingColumn imdbRating\")\n",
    "\n",
    "title = []\n",
    "year = []\n",
    "rating = []\n",
    "\n",
    "\n",
    "for movie in movies:\n",
    "    title1 = movie.find(\"a\").string\n",
    "    title.append(title1)\n",
    "\n",
    "for movie in movies:\n",
    "    year1 = movie.find(\"span\", class_=\"secondaryInfo\").string\n",
    "    year1 = year1.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    year.append(year1)\n",
    "\n",
    "for movie in movies1:\n",
    "    rating1 = movie.find(\"strong\").string\n",
    "    rating.append(rating1)\n",
    "\n",
    "df = pd.DataFrame({'Title':title, 'Year':year, 'Rating':rating})\n",
    "print(df.head(10))\n",
    "df.to_csv(\"movies.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regex web scarping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('China', '15', '12', '3'), ('USA', '15', '12', '3'), ('Brazil', '15', '11', '4'), ('Italy', '15', '11', '4'), ('Turkey', '15', '11', '4'), ('Poland', '15', '9', '6'), ('Belgium', '15', '8', '7'), ('Dominican Republic', '15', '8', '7'), ('Japan', '15', '7', '8'), ('Germany', '15', '7', '8'), ('Netherlands', '15', '6', '9'), ('Thailand', '15', '5', '10'), ('Serbia', '15', '5', '10'), ('Russia', '15', '3', '12'), ('Korea', '15', '3', '12'), ('Bulgaria', '15', '2', '13')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "year = 2019\n",
    "def crawler(url):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        return err\n",
    "    r.encoding = r.apparent_encoding\n",
    "    # put the re expression on one line\n",
    "    pattern = re.compile('href=\"/en/vnl/%s/women/teams/.*?\">(.*?)</a></figcaption>\\s+</figure>\\s+</td>\\s+<td></td>\\s+<td class=\".*?\">(.*?)</td>\\s+<td class=\".*?\">(.*?)</td>\\s+<td class=\".*?\">(.*?)</td>' % year)\n",
    "    p = re.findall(pattern, r.text)\n",
    "    return p\n",
    "\n",
    "\n",
    "url = 'http://www.volleyball.world/en/vnl/%s/women/resultsandranking/round1' % year\n",
    "result = crawler(url)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<span aria-hidden=\"true\">-', '0.33%', '<span aria-hidden=\"true\">-', '0.59%', '<span aria-hidden=\"true\">-', '0.06%', '<span aria-hidden=\"true\">+', '0.68%', '<span aria-hidden=\"true\">+', '0.59%', '<span aria-hidden=\"true\">-', '0.29%', 'Turkish leader acknowledges problems with earthquake relief effort', 'Zelenskiy, in London, wins pledge to train pilots on NATO jets', 'U.S. briefed 40 nations on China spy balloon incident, diplomats and official say', 'Google to soon add generative AI features in search results', 'Church of England explores gender neutral God', 'Big Oil doubles profits in blockbuster 2022', 'Uber focuses on 2023 profits as pandemic pain eases', 'Taco Bell powers Yum Brands quarterly results beat', 'Coty raises profit forecast on resilient demand, price hikes', 'South Korea&#x27;s parliament votes to impeach minister over Halloween crush', 'Pakistan navy to host 50 nations in maritime exercises from Feb 10', 'Ex-Tokyo Olympics official, ad execs arrested in bid-rigging scandal', 'New Zealand recovers $300 mln of cocaine floating at sea', 'Romney tells embattled Republican George Santos he &#x27;shouldn&#x27;t be in Congress&#x27;', 'El Paso massacre suspect expected to plead guilty to federal hate crimes', 'After State of the Union speech, Biden heads to key 2024 campaign states', 'Biden says police who &#x27;violate&#x27; trust should be held accountable in State of the Union', 'Memphis police officer took pictures of handcuffed, beaten Tyre Nichols', 'Texas sues Biden administration for asking pharmacies to fill reproductive health prescriptions', 'Australia to expand rollout of fifth COVID vaccine shot', 'Yanomami health crisis in Brazil can only be solved by expelling miners, official says', 'Biden to push for insulin cost caps, but unlikely to secure Congressional approval', 'Russia asks Pink Floyd&#x27;s Roger Waters to speak on Ukraine arms at UN', 'Farmers drive tractors through Paris in protest at pesticide bans', 'Cyprus ruling party sits on fence in presidential runoff', 'France, Germany protest U.S. green subsidies on Washington trip', 'NBA roundup: Thunder spoil LeBron James&#x27; record night', 'NHL roundup: Sharks end Lightning&#x27;s record home win streak', 'Jabeur pulls out of Doha, Dubai to have minor surgery', 'Bassino pips Shiffrin to win Super-G gold', 'Destruction from above: Aerial views of the earthquake aftermath', '&#x27;Race against time&#x27;: The desperate search for quake survivors', 'In the audience at the State of the Union']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "def crawl_example(url):\n",
    "    response = requests.get(url)\n",
    "    content = response.content.decode(\"utf-8\")\n",
    "    pattern = re.compile(r'<span>(.*?)</span>')\n",
    "    headlines = re.findall(pattern, content)\n",
    "    return headlines\n",
    "\n",
    "# crawl headlines from a news website\n",
    "news_url = \"https://www.reuters.com\"\n",
    "headlines = crawl_example(news_url)\n",
    "print(headlines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4bb1ae6d763fbad0d57a28c9a072db53493e05f8095e6d804c8875c1f9d98ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
